---
---

@string{aps = {American Physical Society,}}
@article{chen2021likelihood,
  abbr={Arxiv},
  title={Likelihood Training of Schr\"odinger Bridge using Forward-Backward SDEs Theory},
  author={Chen, Tianrong and Liu, Guan-Horng and Theodorou, Evangelos A},
  journal={arXiv preprint arXiv:2110.11291},
  year={2021},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2110.11291.pdf},
  abstract={Schr√∂dinger Bridge (SB) is an optimal transport problem that has received increasing attention in deep generative modeling for its mathematical flexibility compared to the Scored-based Generative Model (SGM). However, it remains unclear whether the optimization principle of SB relates to the modern training of deep generative models, which often rely on constructing parameterized log-likelihood objectives.This raises questions on the suitability of SB models as a principled alternative for generative applications. In this work, we present a novel computational framework for likelihood training of SB models grounded on Forward-Backward Stochastic Differential Equations Theory -- a mathematical methodology appeared in stochastic optimal control that transforms the optimality condition of SB into a set of SDEs. Crucially, these SDEs can be used to construct the likelihood objectives for SB that, surprisingly, generalizes the ones for SGM as special cases. This leads to a new optimization principle that inherits the same SB optimality yet without losing applications of modern generative training techniques, and we show that the resulting training algorithm achieves comparable results on generating realistic images on MNIST, CelebA, and CIFAR10.},
  selected={true}
}
@article{liu2021second,
  abbr={NeuraIPS 2021},
  title={Second-Order Neural ODE Optimizer},
  author={Liu, Guan-Horng and Chen, Tianrong and Theodorou, Evangelos A},
  journal={arXiv preprint arXiv:2109.14158},
  year={2021},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2109.14158.pdf},
  arxiv={https://arxiv.org/abs/2105.03788},
  abstract={We propose a novel second-order optimization framework for training the emerging deep continuous-time models, specifically the Neural Ordinary Differential
Equations (Neural ODEs). Since their training already involves expensive gradient
computation by solving a backward ODE, deriving efficient second-order methods
becomes highly nontrivial. Nevertheless, inspired by the recent Optimal Control
(OC) interpretation of training deep networks, we show that a specific continuoustime OC methodology, called Differential Programming, can be adopted to derive
backward ODEs for higher-order derivatives at the same O(1) memory cost. We
further explore a low-rank representation of the second-order derivatives and show
that it leads to efficient preconditioned updates with the aid of Kronecker-based
factorization. The resulting method converges much faster than first-order baselines
in wall-clock time, and the improvement remains consistent across various applications, e.g. image classification, generative flow, and time-series prediction. Our
framework also enables direct architecture optimization, such as the integration
time of Neural ODEs, with second-order feedback policies, strengthening the OC
perspective as a principled tool of analyzing optimization in deep learning.},
  selected={true}
}

@article{liu2021dynamic,
  abbr={ICML 2021},
  title={Dynamic Game Theoretic Neural Optimizer},
  author={Liu, Guan-Horng and Chen, Tianrong and Theodorou, Evangelos A},
  journal={arXiv preprint arXiv:2105.03788},
  year={2021},
  bibtex_show={true},
  abstract={The connection between training deep neural networks (DNNs) and optimal control theory (OCT) has attracted considerable attention as a principled tool of algorithmic design. Despite few attempts being made, they have been limited to architectures where the layer propagation resembles a Markovian dynamical system. This casts doubts on their flexibility to modern networks that heavily rely on non-Markovian dependencies between layers (e.g. skip connections in residual networks). In this work, we propose a novel dynamic game perspective by viewing each layer as a player in a dynamic game characterized by the DNN itself. Through this lens, different classes of optimizers can be seen as matching different types of Nash equilibria, depending on the implicit information structure of each (p)layer. The resulting method, called Dynamic Game Theoretic Neural Optimizer (DGNOpt), not only generalizes OCT-inspired optimizers to richer network class; it also motivates a new training principle by solving a multi-player cooperative game. DGNOpt shows convergence improvements over existing methods on image classification datasets with residual and inception networks. Our work marries strengths from both OCT and game theory, paving ways to new algorithmic opportunities from robust optimal control and bandit-based optimization.},
  arxiv={https://arxiv.org/abs/2105.03788},
  pdf={https://arxiv.org/pdf/2105.03788.pdf},
  poster={https://docs.google.com/presentation/d/1Pm-5h_0jji6ocsarzhdjXZpBpTtwr9kx44fyyU67hH4/edit?usp=sharing},
  slides={https://icml.cc/media/icml-2021/Slides/10261.pdf},
  video={https://icml.cc/virtual/2021/poster/10261},
  selected={true}
}

@inproceedings{chen2021large,
  title={Large-Scale Multi-Agent Deep FBSDEs},
  abbr={ICML 2021},
  author={Chen, Tianrong and Wang, Ziyi O and Exarchos, Ioannis and Theodorou, Evangelos},
  booktitle={International Conference on Machine Learning},
  pages={1740--1748},
  year={2021},
  organization={PMLR},
  bibtex_show={true},
  abstract={In this paper we present a scalable deep learning framework for finding Markovian Nash Equilibria in multi-agent stochastic games using fictitious play. The motivation is inspired by theoretical analysis of Forward Backward Stochastic Differential Equations (FBSDE) and their implementation in a deep learning setting, which is the source of our algorithm's sample efficiency improvement. By taking advantage of the permutation-invariant property of agents in symmetric games, the scalability and performance is further enhanced significantly. We showcase superior performance of our framework over the state-of-the-art deep fictitious play algorithm on an inter-bank lending/borrowing problem in terms of multiple metrics. More importantly, our approach scales up to 3000 agents in simulation, a scale which, to the best of our knowledge, represents a new state-of-the-art. We also demonstrate the applicability of our framework in robotics on a belief space autonomous racing problem.},
  arxiv={https://arxiv.org/abs/2011.10890},
  pdf={https://arxiv.org/pdf/2011.10890.pdf},
  poster={https://github.com/TianrongChen/SFP-FBSDE/blob/main/ICML2021_FP_FBSDE_Poster.pdf},
  slides={https://github.com/TianrongChen/SFP-FBSDE/blob/main/_ICML2021__Presentation_large_Scale_Multi_Agent_Deep_FBSDEs.pdf},
  video={https://slideslive.com/38958966/largescale-multiagent-deep-fbsdes?ref=search},
  selected={true}
}

@article{liu2020ddpnopt,
  title={DDPNOpt: Differential Dynamic Programming Neural Optimizer},
  abbr={ICLR 2021},
  bibtex_show={true},
  author={Liu, Guan-Horng and Chen, Tianrong and Theodorou, Evangelos A},
  journal={arXiv preprint arXiv:2002.08809},
  year={2020},
  abstract={Interpretation of Deep Neural Networks (DNNs) training as an optimal control problem with nonlinear dynamical systems has received considerable attention recently, yet the algorithmic development remains relatively limited. In this work, we make an attempt along this line by reformulating the training procedure from the trajectory optimization perspective. We first show that most widely-used algorithms for training DNNs can be linked to the Differential Dynamic Programming (DDP), a celebrated second-order method rooted in the Approximate Dynamic Programming. In this vein, we propose a new class of optimizer, DDP Neural Optimizer (DDPNOpt), for training feedforward and convolution networks. DDPNOpt features layer-wise feedback policies which improve convergence and reduce sensitivity to hyper-parameter over existing methods. It outperforms other optimal-control inspired training methods in both convergence and complexity, and is competitive against state-of-the-art first and second order methods. We also observe DDPNOpt has surprising benefit in preventing gradient vanishing. Our work opens up new avenues for principled algorithmic design built upon the optimal control theory.},
  arxiv={https://arxiv.org/abs/2002.08809},
  pdf={https://arxiv.org/pdf/2002.08809.pdf},
  poster={https://docs.google.com/presentation/d/1OBW4bXZMDp27smv0za15EjnOV07jC1TpIwA0ww-vlyM/edit?usp=sharing},
  slides={https://drive.google.com/file/d/1hCMEGjE5Zt6WYN4TUAAsvj9QlxhsTlHG/view},
  video={https://iclr.cc/virtual/2021/spotlight/3512},
  selected={true}
}
@inproceedings{pereira2020feynman,
  title={Feynman-Kac Neural Network Architectures for Stochastic Control Using Second-Order FBSDE Theory},
  author={Pereira* Marcus and Wang* Ziyi and Chen* Tianrong and Reed, Emily and Theodorou, Evangelos},
  booktitle={Learning for Dynamics and Control},
  pages={728--738},
  year={2020},
  organization={PMLR}, 
  abbr={L4DC 2020},
  bibtex_show={true},
  abstract={We present a deep recurrent neural network architecture to solve a class of stochastic optimal
control problems described by fully nonlinear Hamilton Jacobi Bellman partial differential equations.
Such PDEs arise when considering stochastic dynamics characterized by uncertainties that are
additive, state dependent, and control multiplicative. Stochastic models with these characteristics
are important in computational neuroscience, biology, finance, and aerospace systems and provide
a more accurate representation of actuation than models with only additive uncertainty. Previous
literature has established the inadequacy of the linear HJB theory for such problems, so instead,
methods relying on the generalized version of the Feynman-Kac lemma have been proposed resulting
in a system of second-order Forward-Backward SDEs. However, so far, these methods suffer from
compounding errors resulting in lack of scalability. In this paper, we propose a deep learning based
algorithm that leverages the second-order FBSDE representation and LSTM-based recurrent neural
networks to not only solve such stochastic optimal control problems but also overcome the problems
faced by traditional approaches, including scalability. The resulting control algorithm is tested on
a high-dimensional linear system and three nonlinear systems from robotics and biomechanics in
simulation to demonstrate feasibility and out-performance against previous methods.},
  pdf={http://proceedings.mlr.press/v120/pereira20a/pereira20a.pdf},
  selected={true}  
}


@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation,}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics,},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers,}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.,},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik,},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.,},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}
